{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
        "the validity of the results."
      ],
      "metadata": {
        "id": "AF38gW9su8iV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis of Variance (ANOVA) is a statistical technique used to compare the means of three or more groups to determine whether there are statistically significant differences among them. However, ANOVA has certain assumptions that need to be met for the results to be valid. Violations of these assumptions can impact the validity of the ANOVA results. The key assumptions of ANOVA are:\n",
        "\n",
        "1. Independence of Observations:\n",
        "   - Assumption: Observations within and between groups must be independent of each other. This means that the values in one group should not be related to the values in another group.\n",
        "   - Violation Example: In a repeated measures design where the same subjects are measured multiple times, the assumption of independence is violated because observations within the same subject are correlated.\n",
        "\n",
        "2. Homogeneity of Variance (Homoscedasticity):\n",
        "   - Assumption: The variances of the different groups being compared are equal (homoscedastic). In other words, the spread of the data within each group is roughly the same.\n",
        "   - Violation Example: In an ANOVA, if one group has much larger variability (spread) compared to the other groups, this is a violation of the homogeneity of variance assumption. This can lead to inflated Type I error rates and affect the validity of ANOVA results.\n",
        "\n",
        "3. Normally Distributed Residuals:\n",
        "   - Assumption: The residuals (the differences between the observed values and the group means) are normally distributed within each group. This assumption is more important when sample sizes are small.\n",
        "   - Violation Example: If the residuals within a group do not follow a normal distribution, it can affect the validity of the F-test and p-values in ANOVA.\n",
        "\n",
        "4. Homogeneity of Group Sizes:\n",
        "   - Assumption: The sample sizes of the groups being compared are roughly equal.\n",
        "   - Violation Example: When sample sizes are unequal, it can lead to reduced power and affect the validity of ANOVA results. Post hoc tests or planned contrasts may be used when there are unequal group sizes.\n",
        "\n",
        "Examples of violations of ANOVA assumptions and their impacts on validity:\n",
        "\n",
        "1. Heteroscedasticity: If the assumption of equal variances is violated (i.e., groups have significantly different variances), ANOVA may be less robust, and it may lead to incorrect conclusions, including false positives or false negatives.\n",
        "\n",
        "2. Non-Normal Residuals: If the assumption of normality is violated and the residuals are not normally distributed, the F-statistic may not follow an F-distribution, leading to incorrect p-values. Transformation of data or using non-parametric tests may be considered in such cases.\n",
        "\n",
        "3. Outliers: Outliers in the data can distort the ANOVA results. They can increase the variability within groups, impact group means, and lead to false conclusions.\n",
        "\n",
        "4. Unequal Group Sizes: Violation of the assumption of equal group sizes can make it more challenging to detect true differences. Additionally, ANOVA may have less power when group sizes are unequal.\n",
        "\n",
        "In cases where ANOVA assumptions are violated, alternative statistical tests or data transformations may be considered to address the issues. For example, non-parametric tests like the Kruskal-Wallis test can be used when the assumption of normality is not met, and robust tests can be used when homoscedasticity is violated. Additionally, data transformations can sometimes help stabilize variances and make the data more normally distributed."
      ],
      "metadata": {
        "id": "qrq1yefxu-Iw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. What are the three types of ANOVA, and in what situations would each be used?"
      ],
      "metadata": {
        "id": "WQWr2qEevD-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis of Variance (ANOVA) is a statistical technique used to compare the means of three or more groups to determine whether there are statistically significant differences among them. There are three main types of ANOVA, each used in different situations:\n",
        "\n",
        "1. One-Way ANOVA:\n",
        "   - Situation: One-Way ANOVA is used when you have one categorical independent variable with three or more levels (groups or categories), and you want to determine if there are significant differences in the means of a single dependent variable among these groups.\n",
        "   - Example: An experiment testing the effect of different fertilizer types (A, B, C, and D) on plant growth. The independent variable is the type of fertilizer, and the dependent variable is plant height.\n",
        "\n",
        "2. Two-Way ANOVA:\n",
        "   - Situation: Two-Way ANOVA is used when you have two categorical independent variables, and you want to investigate their combined effects on a single dependent variable. It helps you determine whether there are main effects for each independent variable and whether there is an interaction effect between the two variables.\n",
        "   - Example: An experiment examining the effect of both temperature (low, high) and humidity (low, high) on the growth of plants. The independent variables are temperature and humidity, and the dependent variable is plant growth.\n",
        "\n",
        "3. Three-Way (or Higher) ANOVA:\n",
        "   - Situation: Three-Way ANOVA, and higher-order ANOVAs, are used when you have three or more categorical independent variables and want to investigate their combined effects on a single dependent variable. They are less common and used in complex experimental designs with multiple factors.\n",
        "   - Example: A study investigating the effects of factors like type of exercise (running, swimming, weightlifting), gender (male, female), and age group (young, middle-aged, senior) on cardiovascular fitness as the dependent variable.\n",
        "\n",
        "In summary:\n",
        "\n",
        "- One-Way ANOVA is used when you have one categorical independent variable with multiple levels.\n",
        "- Two-Way ANOVA is used when you have two categorical independent variables and want to assess their main effects and interaction effect.\n",
        "- Three-Way ANOVA and higher-order ANOVAs are used for experimental designs with three or more categorical independent variables.\n",
        "\n",
        "It's important to choose the appropriate type of ANOVA based on your research question and the design of your study. The choice of ANOVA type depends on the number of factors you are investigating and their interaction. Additionally, it's essential to check and meet the assumptions of ANOVA to ensure the validity of the results."
      ],
      "metadata": {
        "id": "T_oF-TTFvNBM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
      ],
      "metadata": {
        "id": "KVC_SrHMvXYe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The partitioning of variance in Analysis of Variance (ANOVA) is a fundamental concept that involves breaking down the total variability in a dataset into different components to understand the sources of variation. This concept is crucial in ANOVA for several reasons:\n",
        "\n",
        "1. **Understanding the Sources of Variation:**\n",
        "   - ANOVA helps to identify and quantify the sources of variation in a dataset. It decomposes the total variance into components attributed to different factors, such as the main effects and interactions of independent variables.\n",
        "   - By understanding these sources of variation, researchers can determine which factors or conditions contribute significantly to differences in the dependent variable. This information is essential for drawing meaningful conclusions from the analysis.\n",
        "\n",
        "2. **Assessing the Significance of Factors:**\n",
        "   - ANOVA provides a way to assess the statistical significance of the effects of different factors or independent variables. It helps answer questions like, \"Is there a significant difference between groups?\" or \"Do certain factors influence the dependent variable?\"\n",
        "   - Partitioning the variance allows researchers to calculate F-statistics and p-values to determine whether the observed differences are statistically significant.\n",
        "\n",
        "3. **Comparing Variability:**\n",
        "   - ANOVA compares the variability between groups to the variability within groups. The partitioning of variance helps to assess the ratio of these two types of variability.\n",
        "   - The F-statistic, which is calculated by dividing the explained variance (between groups) by the unexplained variance (within groups), is a key metric in ANOVA. A high F-statistic suggests that the differences between groups are larger than what would be expected due to random variation.\n",
        "\n",
        "4. **Interpreting Interaction Effects:**\n",
        "   - In the case of two-way or higher-order ANOVA, partitioning variance is essential for understanding interaction effects. Interaction effects occur when the combined effect of two or more independent variables is not simply the sum of their individual effects.\n",
        "   - By breaking down the variance and examining the interactions, researchers can identify how different factors work together to influence the dependent variable.\n",
        "\n",
        "5. **Modeling and Prediction:**\n",
        "   - ANOVA helps to build models that describe the relationships between independent and dependent variables. These models can be used for predictions, hypothesis testing, and further exploration of the data.\n",
        "   - Understanding the partitioning of variance is essential for model development and validation.\n",
        "\n",
        "In summary, the partitioning of variance in ANOVA is crucial for dissecting the total variation in data, identifying the contributions of different factors, and assessing their statistical significance. It provides a structured framework for hypothesis testing, model building, and drawing valid conclusions about the effects of independent variables on the dependent variable."
      ],
      "metadata": {
        "id": "Td1HdbQnvcpX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
        "sum of squares (SSR) in a one-way ANOVA using Python?"
      ],
      "metadata": {
        "id": "Hw3dNDs0vhJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a one-way Analysis of Variance (ANOVA), you can calculate the Total Sum of Squares (SST), Explained Sum of Squares (SSE), and Residual Sum of Squares (SSR) using Python by following these steps:\n",
        "\n",
        "1. Calculate the Total Sum of Squares (SST):\n",
        "   - SST measures the total variability in the dependent variable. It is the sum of squared differences between each data point and the overall mean.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "# Example data for one-way ANOVA\n",
        "data = [12, 14, 16, 15, 11, 13, 17, 19, 20, 18]\n",
        "\n",
        "# Calculate the overall mean\n",
        "overall_mean = np.mean(data)\n",
        "\n",
        "# Calculate the Total Sum of Squares (SST)\n",
        "SST = sum((x - overall_mean) ** 2 for x in data)\n",
        "```\n",
        "\n",
        "2. Calculate the Explained Sum of Squares (SSE):\n",
        "   - SSE measures the variability explained by the group means in a one-way ANOVA. It is the sum of squared differences between each group mean and the overall mean, weighted by the group sample sizes.\n",
        "\n",
        "```python\n",
        "from collections import Counter\n",
        "\n",
        "# Example data for one-way ANOVA with groups\n",
        "data = [12, 14, 16, 15, 11, 13, 17, 19, 20, 18]\n",
        "groups = ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'D', 'D']\n",
        "\n",
        "# Calculate the group means and sample sizes\n",
        "group_means = {group: np.mean([data[i] for i in range(len(data)) if groups[i] == group]) for group in set(groups)}\n",
        "group_sizes = dict(Counter(groups))\n",
        "\n",
        "# Calculate the Explained Sum of Squares (SSE)\n",
        "SSE = sum(group_sizes[group] * (group_means[group] - overall_mean) ** 2 for group in set(groups))\n",
        "```\n",
        "\n",
        "3. Calculate the Residual Sum of Squares (SSR):\n",
        "   - SSR measures the unexplained variability within each group. It is the sum of squared differences between each data point and its group mean.\n",
        "\n",
        "```python\n",
        "# Calculate the Residual Sum of Squares (SSR)\n",
        "SSR = sum((data[i] - group_means[groups[i]]) ** 2 for i in range(len(data)))\n",
        "```\n",
        "\n",
        "Now you have the SST, SSE, and SSR values. These values can be used to calculate the F-statistic for the one-way ANOVA and perform hypothesis testing to assess whether there are significant differences between the groups."
      ],
      "metadata": {
        "id": "_41KJcq7vnDw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
      ],
      "metadata": {
        "id": "Yj3dmwoQvoYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a two-way ANOVA, you can calculate the main effects and interaction effects using Python by following these steps. A two-way ANOVA involves two independent variables, and it assesses the main effects of each variable and their interaction effect.\n",
        "\n",
        "Here's an example using Python:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# Example data for a two-way ANOVA\n",
        "data = {\n",
        "    'Treatment_A': [10, 12, 14, 15, 16, 18],\n",
        "    'Treatment_B': [8, 9, 10, 12, 13, 14],\n",
        "    'Treatment_C': [11, 12, 13, 14, 15, 16],\n",
        "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female']\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Perform a two-way ANOVA\n",
        "formula = 'Value ~ C(Treatment_A) + C(Treatment_B) + C(Treatment_C) + C(Gender) + C(Treatment_A):C(Gender) + C(Treatment_B):C(Gender) + C(Treatment_C):C(Gender)'\n",
        "model = ols(formula, df).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "# Calculate the main effects\n",
        "main_effect_A = anova_table['PR(>F)']['C(Treatment_A)']\n",
        "main_effect_B = anova_table['PR(>F)']['C(Treatment_B)']\n",
        "main_effect_C = anova_table['PR(>F)']['C(Treatment_C)']\n",
        "main_effect_Gender = anova_table['PR(>F)']['C(Gender)']\n",
        "\n",
        "# Calculate the interaction effects\n",
        "interaction_AB = anova_table['PR(>F)']['C(Treatment_A):C(Treatment_B)']\n",
        "interaction_AG = anova_table['PR(>F)']['C(Treatment_A):C(Gender)']\n",
        "interaction_BG = anova_table['PR(>F)']['C(Treatment_B):C(Gender)']\n",
        "\n",
        "# Print the results\n",
        "print(\"Main Effects:\")\n",
        "print(f\"Main Effect of Treatment A: {main_effect_A:.4f}\")\n",
        "print(f\"Main Effect of Treatment B: {main_effect_B:.4f}\")\n",
        "print(f\"Main Effect of Treatment C: {main_effect_C:.4f}\")\n",
        "print(f\"Main Effect of Gender: {main_effect_Gender:.4f}\")\n",
        "\n",
        "print(\"\\nInteraction Effects:\")\n",
        "print(f\"Interaction Effect AB: {interaction_AB:.4f}\")\n",
        "print(f\"Interaction Effect AG: {interaction_AG:.4f}\")\n",
        "print(f\"Interaction Effect BG: {interaction_BG:.4f}\")\n",
        "```\n",
        "\n",
        "In this code:\n",
        "\n",
        "- We use the `statsmodels` library to perform a two-way ANOVA on the example data. We specify the model formula that includes the main effects of Treatment A, Treatment B, Treatment C, and Gender, as well as their interaction effects.\n",
        "\n",
        "- The `ols` function is used to specify the formula, and the `anova_lm` function is used to obtain the ANOVA table with p-values.\n",
        "\n",
        "- We calculate the main effects by extracting the p-values from the ANOVA table for each factor (Treatment A, Treatment B, Treatment C, and Gender).\n",
        "\n",
        "- We calculate the interaction effects by extracting the p-values from the ANOVA table for each interaction term (AB, AG, and BG).\n",
        "\n",
        "This code provides the main effects and interaction effects for the two-way ANOVA, which can help in assessing the significance of each factor and their interactions in the context of the study. The p-values can be used to determine the statistical significance of the effects."
      ],
      "metadata": {
        "id": "t3KA-1m4v0hN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
        "What can you conclude about the differences between the groups, and how would you interpret these\n",
        "results?"
      ],
      "metadata": {
        "id": "x1NRNnsZv15F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a one-way ANOVA, the F-statistic and its associated p-value are used to determine whether there are significant differences between the groups. Here's how you can interpret the results based on the F-statistic and p-value:\n",
        "\n",
        "1. **F-Statistic (5.23)**: The F-statistic measures the ratio of the variation between the group means to the variation within the groups. It quantifies the extent to which the group means differ from the overall mean. A larger F-statistic indicates larger differences between group means.\n",
        "\n",
        "2. **P-Value (0.02)**: The p-value associated with the F-statistic tells you the probability of observing such an F-statistic (or more extreme) under the null hypothesis. In this case, the null hypothesis typically states that there are no significant differences between the group means.\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "- A small p-value (0.02 in this case) indicates that the observed F-statistic is statistically significant.\n",
        "\n",
        "- You would conclude that there are significant differences between the groups. In other words, at least one group mean is different from the others.\n",
        "\n",
        "- Since the p-value is less than the chosen significance level (commonly 0.05), you would reject the null hypothesis.\n",
        "\n",
        "- In practical terms, it means that the independent variable (the factor or treatment) has a significant effect on the dependent variable, leading to variations in group means that are unlikely to have occurred due to random chance alone.\n",
        "\n",
        "- If the ANOVA is part of a post hoc analysis (i.e., you conducted the ANOVA to compare multiple groups), you may need to perform pairwise comparisons (e.g., Tukey's HSD or Bonferroni correction) to determine which specific groups are significantly different from each other.\n",
        "\n",
        "- It's important to note that the ANOVA itself doesn't tell you which group(s) is/are different from the others, only that there are significant differences somewhere among the groups. Post hoc tests help identify those specific differences.\n",
        "\n",
        "In summary, with an F-statistic of 5.23 and a p-value of 0.02, you can conclude that there are significant differences between the groups, and you would reject the null hypothesis. Further post hoc testing is typically necessary to identify which groups are different from each other."
      ],
      "metadata": {
        "id": "cenV3D-Zv_j_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
        "consequences of using different methods to handle missing data?"
      ],
      "metadata": {
        "id": "7fjr2iIRwGln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling missing data in a repeated measures ANOVA is an important consideration, as missing data can impact the validity of the results and the interpretation of the analysis. The choice of how to handle missing data should be based on the nature of the data and the reasons for missing values. There are several methods for handling missing data in a repeated measures ANOVA, each with its potential consequences:\n",
        "\n",
        "1. **Complete Case Analysis (Listwise Deletion):**\n",
        "   - In this method, any case (subject) with missing data on any variable is removed from the analysis.\n",
        "   - Pros:\n",
        "     - It is straightforward and easy to implement.\n",
        "     - No imputation is needed.\n",
        "   - Cons:\n",
        "     - Reduced sample size and potentially reduced statistical power.\n",
        "     - May introduce bias if the missing data are not missing completely at random (MCAR).\n",
        "\n",
        "2. **Imputation Methods:**\n",
        "   - Imputation methods replace missing values with estimated values based on observed data. Common imputation methods include mean imputation, median imputation, and regression imputation.\n",
        "   - Pros:\n",
        "     - Retains cases with missing data, preserving the sample size.\n",
        "     - Addresses issues related to missing data.\n",
        "   - Cons:\n",
        "     - Imputation introduces additional uncertainty.\n",
        "     - The choice of imputation method may impact results.\n",
        "     - The validity of imputation depends on the assumption that the data are missing at random (MAR).\n",
        "\n",
        "3. **Mixed Effects Models (Longitudinal Data Analysis):**\n",
        "   - Mixed effects models can handle missing data by modeling the within-subject correlation structure and estimating the missing data points.\n",
        "   - Pros:\n",
        "     - Retains cases with missing data.\n",
        "     - Accounts for the correlation between repeated measures within the same subjects.\n",
        "     - Robust against missing data under the missing at random (MAR) assumption.\n",
        "   - Cons:\n",
        "     - Can be computationally intensive.\n",
        "     - Requires an understanding of mixed effects modeling.\n",
        "\n",
        "Potential Consequences of Using Different Methods:\n",
        "\n",
        "- **Complete Case Analysis:** This method may lead to a loss of statistical power and potentially biased results if the missing data are not MCAR. It's generally not recommended when missing data are not completely random.\n",
        "\n",
        "- **Imputation Methods:** Imputation methods can introduce uncertainty, especially if the imputation model is misspecified. The choice of imputation method can impact the results. For instance, mean imputation tends to underestimate variability. Imputation also assumes MAR, which may not always hold.\n",
        "\n",
        "- **Mixed Effects Models:** These models are generally more robust and can handle missing data under the MAR assumption. However, they can be more complex to implement and require a good understanding of mixed effects modeling.\n",
        "\n",
        "The choice of how to handle missing data in a repeated measures ANOVA should be made with careful consideration of the data and research objectives. It is essential to document and justify the chosen method in your analysis to ensure transparency and reproducibility."
      ],
      "metadata": {
        "id": "z7IaF1qBwLS3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
        "an example of a situation where a post-hoc test might be necessary."
      ],
      "metadata": {
        "id": "e7AHFtPuwQYU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Post-hoc tests are used after conducting an analysis of variance (ANOVA) to make pairwise comparisons between groups when the ANOVA reveals a significant overall difference among groups. They help identify which specific groups differ from each other. Common post-hoc tests used after ANOVA include:\n",
        "\n",
        "1. **Tukey's Honestly Significant Difference (Tukey's HSD):**\n",
        "   - Use when you have three or more groups and you want to control the familywise error rate. Tukey's HSD is conservative and maintains a lower Type I error rate.\n",
        "   - Example: In a study comparing the effect of four different treatments on blood pressure, you conduct an ANOVA and find a significant difference. You use Tukey's HSD to determine which treatment groups have significantly different means.\n",
        "\n",
        "2. **Bonferroni Correction:**\n",
        "   - Use when you have three or more groups and you want to control the familywise error rate, but you are willing to accept a more conservative correction.\n",
        "   - Example: In a survey, you analyze the average ratings of five different smartphone brands. After ANOVA, you find a significant difference. You use the Bonferroni correction to adjust for multiple comparisons when testing pairwise differences.\n",
        "\n",
        "3. **Scheffé's Method:**\n",
        "   - Use when you have three or more groups and you want a post-hoc test that is more powerful but less conservative than Tukey's HSD.\n",
        "   - Example: In a psychology experiment, you assess the impact of three different teaching methods on students' test scores. After ANOVA, you find a significant difference. You use Scheffé's method to compare all possible pairs of teaching methods.\n",
        "\n",
        "4. **Dunnett's Test:**\n",
        "   - Use when you have one control group and multiple treatment groups. Dunnett's test compares each treatment group to the control group while controlling for the overall Type I error rate.\n",
        "   - Example: In a drug trial, you have a control group and four different dosages of a new medication. You use Dunnett's test to determine if any of the medication dosages have a different effect compared to the control group.\n",
        "\n",
        "5. **Holm-Bonferroni Method:**\n",
        "   - Use when you have three or more groups and you want to control the familywise error rate while being less conservative than Bonferroni.\n",
        "   - Example: In a marketing study, you examine the effectiveness of different advertising strategies in increasing sales. After ANOVA, you find a significant difference. You use the Holm-Bonferroni method to adjust for multiple comparisons when comparing specific advertising strategies.\n",
        "\n",
        "6. **Fisher's Least Significant Difference (LSD):**\n",
        "   - Use when you have three or more groups and you don't need stringent control over the familywise error rate. It's relatively less conservative.\n",
        "   - Example: In an agricultural study, you test the yield of four different fertilizer treatments. After ANOVA, you find a significant difference. You use Fisher's LSD to identify which pairs of treatments have significantly different yields.\n",
        "\n",
        "The choice of post-hoc test depends on your specific research question, the number of groups, and the desired level of control over the Type I error rate. It's important to choose a post-hoc test that aligns with your research objectives and statistical considerations to make valid pairwise comparisons between groups."
      ],
      "metadata": {
        "id": "fbsJWAywwZ85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
        "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
        "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
        "Report the F-statistic and p-value, and interpret the results."
      ],
      "metadata": {
        "id": "_Kluo9w_wa6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Example weight loss data for three diets (A, B, and C)\n",
        "diet_A = [2.1, 1.8, 2.0, 1.9, 2.2, 1.7, 2.3, 2.0, 1.8, 2.1, 2.0, 1.9, 2.1, 2.0, 1.8, 2.2, 1.7, 2.3, 2.0, 1.9]\n",
        "diet_B = [2.5, 2.3, 2.4, 2.6, 2.7, 2.5, 2.3, 2.4, 2.6, 2.7, 2.5, 2.3, 2.4, 2.6, 2.7, 2.5, 2.3, 2.4, 2.6, 2.7]\n",
        "diet_C = [2.0, 2.1, 2.3, 2.0, 2.2, 2.0, 2.1, 2.3, 2.0, 2.2, 2.0, 2.1, 2.3, 2.0, 2.2, 2.0, 2.1, 2.3, 2.0, 2.2]\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05  # Set the significance level\n",
        "if p_value < alpha:\n",
        "    print(f\"Result: The one-way ANOVA is statistically significant.\")\n",
        "    print(f\"F-statistic: {f_statistic:.2f}\")\n",
        "    print(f\"P-value: {p_value:.4f}\")\n",
        "    print(\"There is at least one significant difference between the mean weight loss of the three diets.\")\n",
        "else:\n",
        "    print(f\"Result: The one-way ANOVA is not statistically significant.\")\n",
        "    print(f\"F-statistic: {f_statistic:.2f}\")\n",
        "    print(f\"P-value: {p_value:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-S3nr8cwjpI",
        "outputId": "53fa3571-7214-44cc-d899-d3d765f51071"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: The one-way ANOVA is statistically significant.\n",
            "F-statistic: 62.07\n",
            "P-value: 0.0000\n",
            "There is at least one significant difference between the mean weight loss of the three diets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
        "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
        "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
        "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
        "interaction effects between the software programs and employee experience level (novice vs.\n",
        "experienced). Report the F-statistics and p-values, and interpret the results."
      ],
      "metadata": {
        "id": "AgOgT9U8wq1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "from statsmodels.formula.api import ols\n",
        "from statsmodels.stats.anova import anova_lm\n",
        "\n",
        "# Example data for two-way ANOVA\n",
        "data = {\n",
        "    'Software': ['A', 'B', 'C'] * 10,\n",
        "    'Experience': ['Novice', 'Experienced'] * 15,\n",
        "    'Time': np.random.normal(loc=30, scale=5, size=30)\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Perform a two-way ANOVA\n",
        "formula = 'Time ~ C(Software) + C(Experience) + C(Software):C(Experience)'\n",
        "model = ols(formula, df).fit()\n",
        "anova_table = anova_lm(model, typ=2)\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05  # Set the significance level\n",
        "\n",
        "# Main effects and interaction effects\n",
        "main_effect_software_pvalue = anova_table['PR(>F)']['C(Software)']\n",
        "main_effect_experience_pvalue = anova_table['PR(>F)']['C(Experience)']\n",
        "interaction_effect_pvalue = anova_table['PR(>F)']['C(Software):C(Experience)']\n",
        "\n",
        "print(f\"Main Effect of Software: p-value = {main_effect_software_pvalue:.4f}\")\n",
        "print(f\"Main Effect of Experience: p-value = {main_effect_experience_pvalue:.4f}\")\n",
        "print(f\"Interaction Effect: p-value = {interaction_effect_pvalue:.4f}\")\n",
        "\n",
        "# Interpret the results based on p-values\n",
        "if main_effect_software_pvalue < alpha:\n",
        "    print(\"There is a significant main effect of Software.\")\n",
        "else:\n",
        "    print(\"There is no significant main effect of Software.\")\n",
        "\n",
        "if main_effect_experience_pvalue < alpha:\n",
        "    print(\"There is a significant main effect of Experience.\")\n",
        "else:\n",
        "    print(\"There is no significant main effect of Experience.\")\n",
        "\n",
        "if interaction_effect_pvalue < alpha:\n",
        "    print(\"There is a significant interaction effect between Software and Experience.\")\n",
        "else:\n",
        "    print(\"There is no significant interaction effect between Software and Experience.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C5S61yJwvrx",
        "outputId": "780eeb01-27b6-4efa-efab-9854d7611b2f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Main Effect of Software: p-value = 0.9960\n",
            "Main Effect of Experience: p-value = 0.5849\n",
            "Interaction Effect: p-value = 0.2251\n",
            "There is no significant main effect of Software.\n",
            "There is no significant main effect of Experience.\n",
            "There is no significant interaction effect between Software and Experience.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
        "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
        "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
        "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
        "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
        "group(s) differ significantly from each other."
      ],
      "metadata": {
        "id": "GEm0WpqZw1KN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To conduct a two-sample t-test in Python to determine if there are any significant differences in test scores between the control group (traditional teaching method) and the experimental group (new teaching method), you can use the `scipy.stats` library. If the results of the t-test are significant, you can follow up with a post-hoc test to determine which group(s) differ significantly from each other.\n",
        "\n",
        "Here's how you can perform the t-test and, if necessary, a post-hoc test:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Example test scores for the control and experimental groups\n",
        "control_group = np.random.normal(loc=75, scale=10, size=50)\n",
        "experimental_group = np.random.normal(loc=80, scale=10, size=50)\n",
        "\n",
        "# Perform a two-sample t-test\n",
        "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
        "\n",
        "# Interpret the results of the t-test\n",
        "alpha = 0.05  # Set the significance level\n",
        "\n",
        "print(f\"Two-Sample T-Test Results:\")\n",
        "print(f\"T-Statistic: {t_statistic:.4f}\")\n",
        "print(f\"P-Value: {p_value:.4f}\")\n",
        "\n",
        "if p_value < alpha:\n",
        "    print(\"The two-sample t-test is statistically significant.\")\n",
        "    print(\"There is a significant difference in test scores between the control and experimental groups.\")\n",
        "else:\n",
        "    print(\"The two-sample t-test is not statistically significant.\")\n",
        "    print(\"There is no significant difference in test scores between the groups.\")\n",
        "\n",
        "# If the t-test is significant, follow up with a post-hoc test\n",
        "if p_value < alpha:\n",
        "    # You can perform additional tests such as Tukey's HSD, Bonferroni, or others to identify which group(s) differ significantly.\n",
        "    # Post-hoc tests require detailed group data, which is not available in this example. Adjust the following code accordingly.\n",
        "\n",
        "    # Example post-hoc test (replace with actual group data)\n",
        "    post_hoc_groups = [control_group, experimental_group]\n",
        "    post_hoc_result = stats.tukeyhsd(np.concatenate(post_hoc_groups), np.concatenate([0] * len(control_group) + [1] * len(experimental_group)))\n",
        "    print(\"\\nPost-Hoc Tukey's HSD Test Results:\")\n",
        "    print(post_hoc_result)\n",
        "```\n",
        "\n",
        "In this code:\n",
        "\n",
        "- We generate example test scores for the control and experimental groups.\n",
        "\n",
        "- We perform a two-sample t-test using the `scipy.stats.ttest_ind` function to compare the means of the two groups.\n",
        "\n",
        "- We set a significance level (alpha) of 0.05 and interpret the results based on the t-statistic and p-value.\n",
        "\n",
        "- If the t-test is significant (p-value < alpha), we consider a significant difference between the groups.\n",
        "\n",
        "- If the t-test is significant, you can follow up with a post-hoc test such as Tukey's HSD or Bonferroni to identify which group(s) differ significantly. To perform a post-hoc test, you would need the actual group data, which should replace the example data used in this code.\n",
        "\n",
        "Please adjust the code with your actual data for a meaningful analysis."
      ],
      "metadata": {
        "id": "0MuZSd1exNYH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
        "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
        "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
        "\n",
        "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
        "hoc test to determine which store(s) differ significantly from each other."
      ],
      "metadata": {
        "id": "oSXGclcnxATK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A repeated measures ANOVA is typically used when you have multiple measurements for the same subjects or items. In your scenario, where you have recorded daily sales for three retail stores over 30 days, a repeated measures ANOVA may not be the most appropriate analysis. Instead, you can use a one-way ANOVA to compare the sales between the three stores on each day.\n",
        "\n",
        "Here's how you can perform a one-way ANOVA in Python to determine if there are any significant differences in daily sales between Store A, Store B, and Store C. If the results are significant, you can follow up with a post-hoc test to identify which store(s) differ significantly from each other:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "from statsmodels.formula.api import ols\n",
        "from statsmodels.stats.anova import anova_lm\n",
        "\n",
        "# Example daily sales data for three stores (A, B, C) over 30 days\n",
        "np.random.seed(0)\n",
        "n_days = 30\n",
        "n_stores = 3\n",
        "\n",
        "data = {\n",
        "    'Day': list(range(1, n_days + 1)) * n_stores,\n",
        "    'Store': ['A'] * n_days + ['B'] * n_days + ['C'] * n_days,\n",
        "    'Sales': np.random.randint(1000, 2000, size=n_days * n_stores)\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Perform a one-way ANOVA\n",
        "formula = 'Sales ~ C(Store)'\n",
        "model = ols(formula, df).fit()\n",
        "anova_table = anova_lm(model, typ=2)\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05  # Set the significance level\n",
        "\n",
        "# Main effect\n",
        "main_effect_pvalue = anova_table['PR(>F)']['C(Store)']\n",
        "\n",
        "print(f\"One-Way ANOVA Results:\")\n",
        "print(f\"P-Value: {main_effect_pvalue:.4f}\")\n",
        "\n",
        "if main_effect_pvalue < alpha:\n",
        "    print(\"The one-way ANOVA is statistically significant.\")\n",
        "    print(\"There is a significant difference in daily sales between the stores.\")\n",
        "else:\n",
        "    print(\"The one-way ANOVA is not statistically significant.\")\n",
        "    print(\"There is no significant difference in daily sales between the stores.\")\n",
        "\n",
        "# If the one-way ANOVA is significant, you can follow up with a post-hoc test.\n",
        "if main_effect_pvalue < alpha:\n",
        "    # You can perform additional tests such as Tukey's HSD, Bonferroni, or others to identify which store(s) differ significantly.\n",
        "    # Post-hoc tests require detailed group data, which is not available in this example. Adjust the following code accordingly.\n",
        "    \n",
        "    # Example post-hoc test (replace with actual group data)\n",
        "    post_hoc_groups = [df['Sales'][df['Store'] == store] for store in ['A', 'B', 'C']]\n",
        "    post_hoc_result = stats.tukeyhsd(np.concatenate(post_hoc_groups), np.concatenate([0] * n_days + [1] * n_days + [2] * n_days))\n",
        "    print(\"\\nPost-Hoc Tukey's HSD Test Results:\")\n",
        "    print(post_hoc_result)\n",
        "```\n",
        "\n",
        "In this code:\n",
        "\n",
        "- We generate example daily sales data for three stores (A, B, C) over 30 days.\n",
        "\n",
        "- We perform a one-way ANOVA using the `statsmodels` library to compare the sales between the three stores.\n",
        "\n",
        "- We set a significance level (alpha) of 0.05 and interpret the results based on the p-value.\n",
        "\n",
        "- If the one-way ANOVA is significant, you can follow up with a post-hoc test to identify which store(s) differ significantly. The example code demonstrates how to perform Tukey's HSD as a post-hoc test.\n",
        "\n",
        "Please adjust the code with your actual data for a meaningful analysis."
      ],
      "metadata": {
        "id": "SbIm3diixQr3"
      }
    }
  ]
}